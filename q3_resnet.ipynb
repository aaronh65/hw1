{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: Even deeper! Resnet18 for PASCAL classification (15 pts)\n",
    "\n",
    "Hopefully we all got much better accuracy with the deeper model! Since 2012, much deeper architectures have been proposed. [ResNet](https://arxiv.org/abs/1512.03385) is one of the popular ones. In this task, we attempt to further improve the performance with the “very deep” ResNet-18 architecture.\n",
    "\n",
    "\n",
    "## 3.1 Build ResNet-18 (1 pts)\n",
    "Write a network modules for the Resnet-18 architecture (refer to the original paper). You can use `torchvision.models` for this section, so it should be very easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0318, -0.0123,  0.0417, -0.0207,  0.0186, -0.0298, -0.0212,  0.0408,\n",
      "        -0.0237,  0.0074,  0.0237,  0.0320,  0.0023, -0.0410,  0.0283,  0.0095,\n",
      "        -0.0364,  0.0172, -0.0391, -0.0114], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "\n",
    "# you could write the whole class....\n",
    "# or one line :D\n",
    "ResNet = models.resnet18()\n",
    "ResNet.fc = nn.Linear(512,20,bias=True)\n",
    "print(ResNet.fc.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Add Tensorboard Summaries (6 pts)\n",
    "You should've already written tensorboard summary generation code into `trainer.py` from q1. However, you probably just added the most basic summary features. Please implement the more advanced summaries listed here:\n",
    "* training loss (should be done)\n",
    "* testing MAP curves (should be done)\n",
    "* learning rate\n",
    "* histogram of gradients\n",
    "\n",
    "## 3.3 Train and Test (8 pts)\n",
    "Use the same hyperparameter settings from Task 2, and train the model for 50 epochs. Report tensorboard screenshots for *all* of the summaries listed above (for image summaries show screenshots at $n \\geq 3$ iterations)\n",
    "\n",
    "**REMEMBER TO SAVE A MODEL AT THE END OF TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0 (0%)]\tLoss: 0.698527\n",
      "Train Epoch: 0 [100 (64%)]\tLoss: 0.254603\n",
      "Train Epoch: 1 [200 (27%)]\tLoss: 0.217977\n",
      "Train Epoch: 1 [300 (91%)]\tLoss: 0.197584\n",
      "Train Epoch: 2 [400 (55%)]\tLoss: 0.195816\n",
      "Train Epoch: 3 [500 (18%)]\tLoss: 0.203704\n",
      "Train Epoch: 3 [600 (82%)]\tLoss: 0.200449\n",
      "Train Epoch: 4 [700 (46%)]\tLoss: 0.182807\n",
      "Train Epoch: 5 [800 (10%)]\tLoss: 0.181640\n",
      "Train Epoch: 5 [900 (73%)]\tLoss: 0.181819\n",
      "Train Epoch: 6 [1000 (37%)]\tLoss: 0.226297\n",
      "Train Epoch: 7 [1100 (1%)]\tLoss: 0.184711\n",
      "Train Epoch: 7 [1200 (64%)]\tLoss: 0.172565\n",
      "Train Epoch: 8 [1300 (28%)]\tLoss: 0.176703\n",
      "Train Epoch: 8 [1400 (92%)]\tLoss: 0.185901\n",
      "Train Epoch: 9 [1500 (55%)]\tLoss: 0.135583\n",
      "Train Epoch: 10 [1600 (19%)]\tLoss: 0.179639\n",
      "Train Epoch: 10 [1700 (83%)]\tLoss: 0.153178\n",
      "Train Epoch: 11 [1800 (46%)]\tLoss: 0.157383\n",
      "Train Epoch: 12 [1900 (10%)]\tLoss: 0.158471\n",
      "Train Epoch: 12 [2000 (74%)]\tLoss: 0.168515\n",
      "Train Epoch: 13 [2100 (38%)]\tLoss: 0.169390\n",
      "Train Epoch: 14 [2200 (1%)]\tLoss: 0.130409\n",
      "Train Epoch: 14 [2300 (65%)]\tLoss: 0.149055\n",
      "Train Epoch: 15 [2400 (29%)]\tLoss: 0.140680\n",
      "Train Epoch: 15 [2500 (92%)]\tLoss: 0.170682\n",
      "Train Epoch: 16 [2600 (56%)]\tLoss: 0.143440\n",
      "Train Epoch: 17 [2700 (20%)]\tLoss: 0.168376\n",
      "Train Epoch: 17 [2800 (83%)]\tLoss: 0.152526\n",
      "Train Epoch: 18 [2900 (47%)]\tLoss: 0.151973\n",
      "Train Epoch: 19 [3000 (11%)]\tLoss: 0.134685\n",
      "Train Epoch: 19 [3100 (75%)]\tLoss: 0.101286\n",
      "Train Epoch: 20 [3200 (38%)]\tLoss: 0.128916\n",
      "Train Epoch: 21 [3300 (2%)]\tLoss: 0.137177\n",
      "Train Epoch: 21 [3400 (66%)]\tLoss: 0.102287\n",
      "Train Epoch: 22 [3500 (29%)]\tLoss: 0.124530\n",
      "Train Epoch: 22 [3600 (93%)]\tLoss: 0.101164\n",
      "Train Epoch: 23 [3700 (57%)]\tLoss: 0.125974\n",
      "Train Epoch: 24 [3800 (20%)]\tLoss: 0.109722\n",
      "Train Epoch: 24 [3900 (84%)]\tLoss: 0.093133\n",
      "Train Epoch: 25 [4000 (48%)]\tLoss: 0.093162\n",
      "Train Epoch: 26 [4100 (11%)]\tLoss: 0.102202\n",
      "Train Epoch: 26 [4200 (75%)]\tLoss: 0.127479\n",
      "Train Epoch: 27 [4300 (39%)]\tLoss: 0.106573\n",
      "Train Epoch: 28 [4400 (3%)]\tLoss: 0.135511\n",
      "Train Epoch: 28 [4500 (66%)]\tLoss: 0.112894\n",
      "Train Epoch: 29 [4600 (30%)]\tLoss: 0.130944\n",
      "Train Epoch: 29 [4700 (94%)]\tLoss: 0.113116\n",
      "Train Epoch: 30 [4800 (57%)]\tLoss: 0.084283\n",
      "Train Epoch: 31 [4900 (21%)]\tLoss: 0.087552\n",
      "Train Epoch: 31 [5000 (85%)]\tLoss: 0.105739\n",
      "Train Epoch: 32 [5100 (48%)]\tLoss: 0.081625\n",
      "Train Epoch: 33 [5200 (12%)]\tLoss: 0.088208\n",
      "Train Epoch: 33 [5300 (76%)]\tLoss: 0.078556\n",
      "Train Epoch: 34 [5400 (39%)]\tLoss: 0.105101\n",
      "Train Epoch: 35 [5500 (3%)]\tLoss: 0.068774\n",
      "Train Epoch: 35 [5600 (67%)]\tLoss: 0.091674\n",
      "Train Epoch: 36 [5700 (31%)]\tLoss: 0.075016\n",
      "Train Epoch: 36 [5800 (94%)]\tLoss: 0.074154\n",
      "Train Epoch: 37 [5900 (58%)]\tLoss: 0.075834\n",
      "Train Epoch: 38 [6000 (22%)]\tLoss: 0.064743\n",
      "Train Epoch: 38 [6100 (85%)]\tLoss: 0.082696\n",
      "Train Epoch: 39 [6200 (49%)]\tLoss: 0.074663\n",
      "Train Epoch: 40 [6300 (13%)]\tLoss: 0.049699\n",
      "Train Epoch: 40 [6400 (76%)]\tLoss: 0.077009\n",
      "Train Epoch: 41 [6500 (40%)]\tLoss: 0.074367\n",
      "Train Epoch: 42 [6600 (4%)]\tLoss: 0.086027\n",
      "Train Epoch: 42 [6700 (68%)]\tLoss: 0.062761\n",
      "Train Epoch: 43 [6800 (31%)]\tLoss: 0.076776\n",
      "Train Epoch: 43 [6900 (95%)]\tLoss: 0.090529\n",
      "Train Epoch: 44 [7000 (59%)]\tLoss: 0.072387\n",
      "Train Epoch: 45 [7100 (22%)]\tLoss: 0.054696\n",
      "Train Epoch: 45 [7200 (86%)]\tLoss: 0.063657\n",
      "Train Epoch: 46 [7300 (50%)]\tLoss: 0.073254\n",
      "Train Epoch: 47 [7400 (13%)]\tLoss: 0.044721\n",
      "Train Epoch: 47 [7500 (77%)]\tLoss: 0.076039\n",
      "Train Epoch: 48 [7600 (41%)]\tLoss: 0.068919\n",
      "Train Epoch: 49 [7700 (4%)]\tLoss: 0.067518\n",
      "Train Epoch: 49 [7800 (68%)]\tLoss: 0.046372\n",
      "test map: 0.5349790510593231\n"
     ]
    }
   ],
   "source": [
    "args = ARGS(batch_size=32, test_batch_size=32, epochs=50, val_every=250, lr=1e-4, size=227, save_freq=10)\n",
    "model = ResNet\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=args.gamma)\n",
    "test_ap, test_map = trainer.train(args, model, optimizer, scheduler, model_name='runs/q3/model')\n",
    "print('test map:', test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/q3_tb_map.png)\n",
    "![title](imgs/q3_tb_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/q3_tb_lr.png)\n",
    "![title](imgs/q3_tb_hist.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

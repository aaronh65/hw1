{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Lets go deeper! CaffeNet for PASCAL classification (20 pts)\n",
    "\n",
    "**Note:** You are encouraged to reuse code from the previous task. Finish Q1 if you haven't already!\n",
    "\n",
    "\n",
    "As you might have seen, the performance of the SimpleCNN model was pretty low for PASCAL. This is expected as PASCAL is much more complex than FASHION MNIST, and we need a much beefier model to handle it.\n",
    "\n",
    "In this task we will be constructing a variant of the [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) architecture, known as CaffeNet. If you are familiar with Caffe, a prototxt of the network is available [here](https://github.com/BVLC/caffe/blob/master/models/bvlc_reference_caffenet/train_val.prototxt). A visualization of the network is available [here](http://ethereon.github.io/netscope/#/preset/caffenet).\n",
    "\n",
    "\n",
    "## 2.1 Build CaffeNet (5 pts)\n",
    "Here is the exact model we want to build. In this task, `torchvision.models.xxx()` is NOT allowed. Define your own CaffeNet! We use the following operator notation for the architecture:\n",
    "1. Convolution: A convolution with kernel size $k$, stride $s$, output channels $n$, padding $p$ is represented as $conv(k, s, n, p)$.\n",
    "2. Max Pooling: A max pool operation with kernel size $k$, stride $s$ as $maxpool(k, s)$.\n",
    "3. Fully connected: For $n$ output units, $FC(n)$.\n",
    "4. ReLU: For rectified linear non-linearity $relu()$\n",
    "\n",
    "```\n",
    "ARCHITECTURE:\n",
    "-> image\n",
    "-> conv(11, 4, 96, ’VALID’)\n",
    "-> relu()\n",
    "-> max_pool(3, 2)\n",
    "-> conv(5, 1, 256, 'SAME')\n",
    "-> relu()\n",
    "-> max_pool(3, 2)\n",
    "-> conv(3, 1, 384, 'SAME')\n",
    "-> relu()\n",
    "-> conv(3, 1, 384, 'SAME')\n",
    "-> relu()\n",
    "-> conv(3, 1, 256, ’SAME’)\n",
    "-> relu()\n",
    "-> max_pool(3, 2)\n",
    "-> flatten()\n",
    "-> fully_connected(4096)\n",
    "-> relu()\n",
    "-> dropout(0.5)\n",
    "-> fully_connected(4096)\n",
    "-> relu()\n",
    "-> dropout(0.5)\n",
    "-> fully_connected(20)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "\n",
    "class CaffeNet(nn.Module):\n",
    "    def __init__(self, num_classes=20, size=227, c_dim=3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # size\n",
    "        self.conv1 = nn.Conv2d(c_dim, 96, 11, 4)\n",
    "        # size is 55\n",
    "        self.conv2 = nn.Conv2d(96 , 256, 5, 1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(256, 384, 3, 1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 384, 3, 1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(384, 256, 3, 1, padding=1)\n",
    "        \n",
    "        map_size = (size - 11) / 4 + 1\n",
    "        self.flat_dim = int(map_size**2 * 256)\n",
    "        \n",
    "        self.nonlinear = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(3,2)\n",
    "        self.pool2 = nn.MaxPool2d(3,2)\n",
    "        self.pool3 = nn.MaxPool2d(3,2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flat_dim, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(-1, self.flat_dim)\n",
    "        x = self.fc1(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Save the Model (5 pts)\n",
    "Finish code stubs for saving the model periodically into trainer.py. **You will need these models later**\n",
    "\n",
    "\n",
    "## 2.3 Train and Test (5pts)\n",
    "Show clear screenshots of testing MAP and training loss for 50 epochs. Please evaluate your model to calculate the MAP on the testing dataset every 250 iterations. Use the following hyperparamters:\n",
    "* batch_size=32\n",
    "* Adam optimizer with lr=0.0001\n",
    "\n",
    "**NOTE: SAVE AT LEAST 5 EVENLY SPACED CHECKPOINTS DURING TRAINING (1 at end)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS(batch_size=32, test_batch_size=32, epochs=5, val_every=250, lr=1e-4)\n",
    "model = CaffeNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "test_ap, test_map = trainer.train(args, model, optimizer, scheduler)\n",
    "print('test map:', test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSERT YOUR TENSORBOARD SCREENSHOTS HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Visualizing: Conv-1 filters (5pts)\n",
    "Extract and compare the conv1 filters, at different stages of the training (at least from 3 different iterations). Show at least 5 filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlr",
   "language": "python",
   "name": "vlr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Shoulders of Giants (15 points)\n",
    "As we have already seen, deep networks can sometimes be hard to optimize. Often times they heavily overfit on small training sets. Many approaches have been proposed to counter this, eg, [Krahenbuhl et al. (ICLRâ€™16)](http://arxiv.org/pdf/1511.06856.pdf), self-supervised learning, etc. However, the most effective approach remains pre-training the network on large, well-labeled supervised datasets such as ImageNet. \n",
    "\n",
    "While training on the full ImageNet data is beyond the scope of this assignment, people have already trained many popular/standard models and released them online. In this task, we will initialize a ResNet-18 model with pre-trained ImageNet weights (from `torchvision`), and finetune the network for PASCAL classification.\n",
    "\n",
    "## 4.1 Load Pre-trained Model (7 pts)\\\n",
    "Load the pre-trained weights up to the second last layer, and initialize last weights and biases from scratch.\n",
    "\n",
    "The model loading mechanism is based on names of the weights. It is easy to load pretrained models from `torchvision.models`, even when your model uses different names for weights. Please briefly explain how to load the weights correctly if the names do not match ([hint](https://discuss.pytorch.org/t/loading-weights-from-pretrained-model-with-different-module-names/11841)).\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "\n",
    "# Pre-trained weights up to second-to-last layer\n",
    "# final layers should be initialized from scratcH!\n",
    "class PretrainedResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ResNet = models.resnet18(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(ResNet.children())[:-1])\n",
    "        for param in self.backbone:\n",
    "            param.requires_grad = False\n",
    "        self.classifier = nn.Linear(512,20,bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = features.view(-1, 512)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use similar hyperparameter setup as in the scratch case. Show the learning curves (training loss, testing MAP) for 10 epochs. Please evaluate your model to calculate the MAP on the testing dataset every 100 iterations.\n",
    "\n",
    "**REMEMBER TO SAVE MODEL AT END OF TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0 (0%)]\tLoss: 0.738947\n",
      "Train Epoch: 0 [100 (64%)]\tLoss: 0.158812\n",
      "Train Epoch: 1 [200 (27%)]\tLoss: 0.077691\n",
      "Train Epoch: 1 [300 (91%)]\tLoss: 0.099643\n",
      "Train Epoch: 2 [400 (55%)]\tLoss: 0.080847\n",
      "Train Epoch: 3 [500 (18%)]\tLoss: 0.040495\n",
      "Train Epoch: 3 [600 (82%)]\tLoss: 0.040389\n",
      "Train Epoch: 4 [700 (46%)]\tLoss: 0.038934\n",
      "Train Epoch: 5 [800 (10%)]\tLoss: 0.021909\n",
      "Train Epoch: 5 [900 (73%)]\tLoss: 0.016995\n",
      "Train Epoch: 6 [1000 (37%)]\tLoss: 0.014961\n",
      "Train Epoch: 7 [1100 (1%)]\tLoss: 0.013639\n",
      "Train Epoch: 7 [1200 (64%)]\tLoss: 0.015578\n",
      "Train Epoch: 8 [1300 (28%)]\tLoss: 0.008688\n",
      "Train Epoch: 8 [1400 (92%)]\tLoss: 0.011300\n",
      "Train Epoch: 9 [1500 (55%)]\tLoss: 0.007435\n",
      "test map: 0.817214616125489\n"
     ]
    }
   ],
   "source": [
    "args = ARGS(batch_size=32, test_batch_size=32, epochs=10, val_every=100, lr=1e-4, size=227, save_freq=1)\n",
    "model = PretrainedResNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=args.gamma)\n",
    "test_ap, test_map = trainer.train(args, model, optimizer, scheduler, model_name='runs/q4/model')\n",
    "print('test map:', test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR TB SCREENSHOTS HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/q4_tb_map.png)\n",
    "![title](imgs/q4_tb_loss.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
